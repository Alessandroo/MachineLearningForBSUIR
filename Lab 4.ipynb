{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №4 “Нейронные сети”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as clr\n",
    "from scipy import optimize\n",
    "from scipy.io import loadmat\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Набор данных ex4data1.mat (такой же, как в лабораторной работе №2)\n",
    "представляет собой файл формата *.mat (т.е. сохраненного из Matlab). Набор\n",
    "содержит 5000 изображений 20x20 в оттенках серого. Каждый пиксель\n",
    "представляет собой значение яркости (вещественное число). Каждое\n",
    "изображение сохранено в виде вектора из 400 элементов. В результате\n",
    "загрузки набора данных должна быть получена матрица 5000x400. Далее\n",
    "расположены метки классов изображений от 1 до 9 (соответствуют цифрам\n",
    "от 1 до 9), а также 10 (соответствует цифре 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Загрузите данные ex4data1.mat из файла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_file_name = \"Data\\Lab 4\\ex4data1.mat\"\n",
    "mat = loadmat(task1_file_name)  # load mat-file\n",
    "X = mat['X']\n",
    "y = mat['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Загрузите веса нейронной сети из файла ex4weights.mat, который\n",
    "содержит две матрицы Θ<sup>(1)</sup>(25, 401) и Θ<sup>(2)</sup>(10, 26). Какова структура полученной нейронной сети?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_weights_file_name = \"Data\\Lab 4\\ex4weights.mat\"\n",
    "mat = loadmat(task1_weights_file_name)  # load mat-file\n",
    "Theta1 = mat['Theta1']\n",
    "Theta2 = mat['Theta2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Реализуйте функцию прямого распространения с сигмоидом в качестве функции активации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = lambda z: 1 / (1 + np.exp(-z))\n",
    "perceptron = lambda t, x, func: func(np.dot(t, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 400), (5000, 1), (25, 401), (10, 26))"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, Theta1.shape, Theta2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_perform(weights, input_data, func):\n",
    "    result = np.zeros((weights.shape[0], input_data.shape[1]))\n",
    "    z = np.dot(weights, input_data)\n",
    "    a = perceptron(weights, input_data, func)\n",
    "    return z, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_layer = np.hstack((np.ones((X.shape[0], 1)), X)).T\n",
    "z2, first_layer = layer_perform(Theta1, zero_layer, sigmoid)\n",
    "first_layer = np.hstack((np.ones((first_layer.shape[1], 1)), first_layer.T)).T\n",
    "z3, second_layer = layer_perform(Theta2, first_layer, sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.argmax(second_layer.T, axis = 1) + 1 \n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Вычислите процент правильных классификаций на обучающей выборке. Сравните полученный результат с логистической регрессией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.52"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pred.flatten() == y.flatten()) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Перекодируйте исходные метки классов по схеме one-hot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "class_matrix = np.eye(k)\n",
    "class_model = {}\n",
    "for i in range(k):\n",
    "    class_model[i+1] = class_matrix[:, i].reshape(1, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " 2: array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " 3: array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " 4: array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]]),\n",
       " 5: array([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]),\n",
       " 6: array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]]),\n",
       " 7: array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]]),\n",
       " 8: array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]]),\n",
       " 9: array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]]),\n",
       " 10: array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_in_hot = []\n",
    "for item in y.T.tolist()[0]:\n",
    "    y_in_hot.append(class_model[item])\n",
    "y_in_hot = np.array(y_in_hot)\n",
    "y_in_hot = y_in_hot.reshape(5000, 10)\n",
    "y_in_hot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Реализуйте функцию стоимости для данной нейронной сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "lost_func = lambda t, x, y: (-1 / m) * (\n",
    "                                 np.dot(y.T,np.log(sigmoid(np.dot(t.T, x)).T)) \n",
    "                                 + \n",
    "                                 np.dot((1 - y).T, np.log(1 - sigmoid(np.dot(t.T, x)).T))\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Добавьте L2-регуляризацию в функцию стоимости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = lambda z: 1 / (1 + np.exp(-z))\n",
    "lost_func = lambda t, x, y, l: (-1 / m) * (\n",
    "                                 np.dot(y.T,np.log(g(np.dot(t.T, x)).T)) \n",
    "                                 + \n",
    "                                 np.dot((1 - y).T, np.log(1 - g(np.dot(t.T, x)).T))\n",
    "                                ) + l*np.sum(np.square(t))/(2*m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Реализуйте функцию вычисления производной для функции активации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivative_func = lambda z, func: func(z) * (1-func(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Инициализируйте веса небольшими случайными числами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b - a) * random_sample() + a [-1; 1)\n",
    "T1 = 4 * np.random.random_sample(Theta1.shape) - 2\n",
    "T2 = 4 * np.random.random_sample(Theta2.shape) - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.Реализуйте алгоритм обратного распространения ошибки для данной\n",
    "конфигурации сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = [T1, T2, None]\n",
    "iteration = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1993106  0.36892792 0.74291086 ... 0.17514858 0.18414321 0.03360167]\n",
      " [0.98698918 0.95248829 0.47492096 ... 0.98650254 0.7730153  0.67289879]\n",
      " [0.28442474 0.18917908 0.00626088 ... 0.27782049 0.66294811 0.04954411]\n",
      " ...\n",
      " [0.88008896 0.77080539 0.99827166 ... 0.80278778 0.56444731 0.94004053]\n",
      " [0.09660648 0.13414081 0.0047288  ... 0.02015726 0.00460698 0.01193369]\n",
      " [0.174368   0.17245953 0.00104751 ... 0.00137724 0.0010163  0.03051063]]\n",
      "0.3719924716653812\n",
      "2\n",
      "0.0902\n"
     ]
    }
   ],
   "source": [
    "zero_layer = np.hstack((np.ones((X.shape[0], 1)), X)).T\n",
    "alpha = 0.1\n",
    "a = [zero_layer, None, None]\n",
    "z = [None, None, None]\n",
    "# T = [T1, T2, None]\n",
    "beta = [None, None, None]\n",
    "delta = [np.zeros(T1.shape), np.zeros(T2.shape), None]\n",
    "D = [np.zeros(T1.shape), np.zeros(T2.shape), None]\n",
    "m = X.shape[0]\n",
    "L=3\n",
    "for num_layer in range(1, L):\n",
    "    z[num_layer], a[num_layer] = layer_perform(T[num_layer-1], a[num_layer-1], sigmoid)\n",
    "    if num_layer < L - 1:\n",
    "        a[num_layer] = np.hstack((np.ones((a[num_layer].shape[1], 1)), a[num_layer].T)).T\n",
    "        z[num_layer] = np.hstack((np.ones((z[num_layer].shape[1], 1)), z[num_layer].T)).T\n",
    "beta[-1] = np.abs(a[-1]-y_in_hot.T)\n",
    "print(a[-1])\n",
    "print(np.mean(beta[-1]))\n",
    "for num_layer in reversed(range(1, L-1)):\n",
    "    beta[num_layer] = np.dot(T[num_layer].T, beta[num_layer+1]) * derivative_func(z[num_layer], sigmoid)\n",
    "for num_layer in range(L-1):\n",
    "    if num_layer < L-2:\n",
    "        delta[num_layer] = delta[num_layer] + np.dot(b[num_layer+1][:-1,:], a[num_layer].T)\n",
    "    else:\n",
    "        delta[num_layer] = delta[num_layer] + np.dot(b[num_layer+1], a[num_layer].T)\n",
    "for num_layer in range(L-1):\n",
    "    D[num_layer] = delta[num_layer] / m\n",
    "for num_layer in range(L-1):\n",
    "    T[num_layer] = T[num_layer] - alpha * D[num_layer]\n",
    "iteration += 1\n",
    "print(iteration)\n",
    "pred = np.argmax(a[-1].T, axis = 1) \n",
    "print(np.mean(pred.flatten() == y.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25, 401), (25, 401))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(beta[1][:-1,:], a[0].T).shape, delta[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.Для того, чтобы удостоверится в правильности вычисленных значений\n",
    "градиентов используйте метод проверки градиента с параметром ε = 10<sup>-4</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_layer in range(L-1):\n",
    "    t = T[num_layer]\n",
    "    for i in range(t.shape[1]):\n",
    "        for j in range(t.shape[0]):\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.Добавьте L2-регуляризацию в процесс вычисления градиентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13.Проверьте полученные значения градиента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14.Обучите нейронную сеть с использованием градиентного спуска или\n",
    "других более эффективных методов оптимизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15.Вычислите процент правильных классификаций на обучающей\n",
    "выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16.Визуализируйте скрытый слой обученной сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17.Подберите параметр регуляризации. Как меняются изображения на\n",
    "скрытом слое в зависимости от данного параметра?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
